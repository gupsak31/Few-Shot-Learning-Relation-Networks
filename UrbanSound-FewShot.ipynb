{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UrbanSound-FewShot.ipynb","provenance":[],"collapsed_sections":["MXkAa6tfDtWf","U57R-okWpZN2","qkjDkwfF7C4T"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X87PzfZtDJn4","outputId":"be4f4968-2a48-499d-9a84-925a86aa6cca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MXkAa6tfDtWf"},"source":["# **Data Loader**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"oGRNm2BxI75l"},"source":["''' Split for number of classes in training and test '''\n","num_sampleclasses = 7\n","num_fewshotclasses = 3 #atleast two\n","\n","''' Number of audio-label pairs in Training (sample) and Test (fewshot) '''\n","sample_train = 600\n","sample_val = 0\n","sample_test = 0\n","\n","fewshot_train = 0\n","fewshot_val = 60\n","fewshot_test = 200\n","\n","''' Audio to STFT hyperparameters '''\n","sampling_rate = 44100\n","row_len = 513 # Number of columns: 1 + n_fft/2\n","col_len = 401 # Number of rows: 1 + (sampling_rate*audio_duration)/(0.01*sampling_rate); 0.01*sampling_rate = hop \n","# audio_length = sampling_rate*audio_duration\n","# audio_duration = 4 seconds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0CjBC8fkwU3","outputId":"64f4e810-f586-40cf-b084-81352ddc0c62"},"source":["%cd \"/content/drive/MyDrive/UrbanSound8K\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/UrbanSound8K\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DTrJvygok3nq"},"source":["import numpy as np\n","import pandas as pd\n","\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","\n","import librosa\n","\n","from sklearn.utils import shuffle\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import Sampler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWzu7OMpmlxV"},"source":["Number of audio-label pairs for each class. Clearly, *car horn* and *gun shot* are *rare classes*. We will always include them in test dataset. \n","\n","\n","The third class for the test set in selected randomly. *FEWSHOT_CLASSES* are test set classes and *SAMPLE_CLASSES* are training set classes."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGV73tXalaKp","outputId":"d62d22d4-3295-471b-b470-b61a8a079dec"},"source":["df = pd.read_csv(\"UrbanSound8K.csv\")\n","df[\"class\"].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["children_playing    1000\n","dog_bark            1000\n","jackhammer          1000\n","air_conditioner     1000\n","street_music        1000\n","engine_idling       1000\n","drilling            1000\n","siren                929\n","car_horn             429\n","gun_shot             374\n","Name: class, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2b0mL09Ja8o","outputId":"0e229af8-8cdd-4d07-ba0b-d0f8826a16d5"},"source":["CLASSES = list(df[\"class\"].unique())\n","\n","CLASSES.remove(\"gun_shot\")\n","CLASSES.remove(\"car_horn\")\n","\n","random.shuffle(CLASSES)\n","SAMPLE_CLASSES = CLASSES[:num_sampleclasses]\n","FEWSHOT_CLASSES = CLASSES[num_sampleclasses:]\n","\n","FEWSHOT_CLASSES.append(\"gun_shot\")\n","FEWSHOT_CLASSES.append(\"car_horn\")\n","\n","print(SAMPLE_CLASSES, FEWSHOT_CLASSES)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['drilling', 'children_playing', 'siren', 'engine_idling', 'jackhammer', 'street_music', 'air_conditioner'] ['dog_bark', 'gun_shot', 'car_horn']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXWgBTcEl1Cs"},"source":["def get_data(class_name, n_train, n_val, n_test):\n","    df_class = df.loc[df[\"class\"] == class_name]\n","    indexes = [i for i in range(df_class.shape[0])]\n","    random.shuffle(indexes)\n","\n","    df_class_train = df_class.iloc[indexes[:n_train]]\n","    df_class_val = df_class.iloc[indexes[n_train:(n_train + n_val)]]\n","    df_class_test = df_class.iloc[indexes[(n_train + n_val):(n_train + n_val + n_test)]]\n","\n","    return df_class_train, df_class_val, df_class_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4zJJ56eywxe"},"source":["SAMPLE_data_train = [None]*num_sampleclasses\n","SAMPLE_data_val = [None]*num_sampleclasses\n","SAMPLE_data_test = [None]*num_sampleclasses\n","\n","for i in range(num_sampleclasses):\n","    SAMPLE_data_train[i], SAMPLE_data_val[i], SAMPLE_data_test[i] = get_data(SAMPLE_CLASSES[i], sample_train, sample_val, sample_test)\n","\n","FS_data_train = [None]*num_fewshotclasses\n","FS_data_val = [None]*num_fewshotclasses\n","FS_data_test = [None]*num_fewshotclasses\n","\n","for i in range(num_fewshotclasses):\n","    FS_data_train[i], FS_data_val[i], FS_data_test[i] = get_data(FEWSHOT_CLASSES[i], fewshot_train, fewshot_val, fewshot_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vlJ8xZMgOlgy"},"source":["df_train = pd.concat((SAMPLE_data_train + FS_data_train), ignore_index = True)\n","df_val = pd.concat((SAMPLE_data_val + FS_data_val), ignore_index = True)\n","df_test = pd.concat((SAMPLE_data_test + FS_data_test), ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Fnhpv2unwgi"},"source":["So far, we have randomly selected\n"," \n","\n","*   600 (*sample_train*) audio-label pairs per class for training dataset.\n","*   20 (*fewshot_val*) audio-label pairs per class for validation dataset.\n","*   200 (*fewshot_test*) audio-label pairs per class for test dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWC-OiiUO8R9","outputId":"4e231942-1d6f-41d8-f808-93629efc63ad"},"source":["print(list(df_train[\"class\"].value_counts()))\n","print(list(df_val[\"class\"].value_counts()))\n","print(list(df_test[\"class\"].value_counts()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[600, 600, 600, 600, 600, 600, 600]\n","[60, 60, 60]\n","[200, 200, 200]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w6P5IkyhxVVj"},"source":["# df_train.to_csv(\"\", index = False)\n","# df_val.to_csv(\"\", index = False)\n","# df_test.to_csv(\"\", index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_8wQA4hydIf"},"source":["df_tmp = pd.read_csv(\"UrbanSound8K.csv\")\n","_labels = list(df_tmp[\"class\"].unique())\n","label_idx = {label: i for i, label in enumerate(_labels)}\n","n_classes = len(df_tmp[\"class\"].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGK4u5qWodDP"},"source":["**Divide each of train, validation and test into smaller DataFrames for Few-Shot learning**"]},{"cell_type":"code","metadata":{"id":"8KY2Quu8OCYW"},"source":["def CreatDataFolders(df, n, samples, per_df):\n","    df[\"label_idx\"] = df[\"class\"].apply(lambda x : label_idx[x])\n","    df.sort_values(by = \"label_idx\", inplace = True)\n","\n","    a = 0\n","    b = per_df\n","    dfs = []\n","    for _ in range(n):\n","        tmp = []\n","        for i in range(int(samples/per_df)):\n","            tmp.append(df.iloc[a:b])\n","            a += per_df\n","            b += per_df\n","        dfs.append(tmp)\n","    \n","    return dfs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIkrFfQHK0fM"},"source":["dfs_train = CreatDataFolders(df_train, num_sampleclasses, sample_train, 30)\n","dfs_val = CreatDataFolders(df_val, num_fewshotclasses, fewshot_val, 20)\n","dfs_test = CreatDataFolders(df_test, num_fewshotclasses, fewshot_test, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U57R-okWpZN2"},"source":["# **Utility Functions**\n","\n","---"]},{"cell_type":"code","metadata":{"id":"ntkjDQrsSE3D"},"source":["def wav2feat(wavfile, Fs = sampling_rate):\n","    ''' input: file path to an audio file (.wav file)\n","        output: padded STFT '''\n","        \n","    x, _ = librosa.core.load(wavfile, sr = Fs, mono = True)\n","    hop = int(0.01*Fs) # 10ms\n","    win = int(0.02*Fs) # 20ms\n","    X = librosa.stft(x, n_fft = 1024, hop_length = hop, win_length = win, window = 'hann', center = True, pad_mode = \"reflect\")\n","    X = np.abs(X)\n","\n","    if X.shape[1] > col_len:\n","        max_offset = X.shape[1] - col_len\n","        offset = np.random.randint(max_offset)\n","        X = X[:, offset : (col_len + offset)]\n","    else:\n","        if X.shape[1] < col_len:\n","            max_offset = col_len - X.shape[1]\n","            offset = np.random.randint(max_offset)\n","        else:\n","            offset = 0\n","        X = np.pad(X, ((0, 0), (offset, col_len - X.shape[1] - offset)), \"constant\")\n","\n","    return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSP4FyxhuBor"},"source":["class UrbanSoundTask(object):\n","    ''' \"num_classes is no. of classes per episode randomly\n","        selected from the pool of train classes.\n","        \"train_num\"/\"test_num\" is number of samples per class. '''\n","\n","    def __init__(self, num_classes = 3, train_num = 5, test_num = 15, dfs = None, split ='train'):\n","        self.num_classes = num_classes\n","        self.train_num = train_num\n","        self.test_num = test_num\n","        self.dfs = dfs\n","        self.mode = split\n","\n","        self.train = pd.DataFrame()\n","        self.test = pd.DataFrame()\n","        self.train_labels = []\n","        self.test_labels = []\n","\n","        if (self.mode == 'train'):\n","            sample_idx = random.sample([i for i in range(num_sampleclasses)], self.num_classes)\n","        else:\n","            sample_idx = random.sample([i for i in range(num_fewshotclasses)], self.num_classes)\n","\n","        list_dfs = []\n","        for idx in sample_idx:\n","            list_dfs.append(random.sample(self.dfs[idx], 1))\n","        \n","        for i, df in enumerate(list_dfs):\n","            df = shuffle(df[0])\n","            self.train = self.train.append(df[:train_num])\n","            self.train_labels.extend([i for j in range(train_num)])\n","\n","            self.test = self.test.append(df[train_num:(train_num + test_num)])\n","            self.test_labels.extend([i for j in range(test_num)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DojWzImaQjhU"},"source":["class FewShotDataset(Dataset):\n","    ''' It is a custom pytorch Dataset.\n","        input: An object of \"UrbanSoundTask\" class. '''\n","\n","    def __init__(self, task, split = 'train'):\n","        self.task = task\n","        self.mode = split\n","        self.df = self.task.train if self.mode == 'train' else self.task.test\n","        self.labels = self.task.train_labels if self.mode == 'train' else self.task.test_labels\n","\n","    def __len__(self):\n","        return len(self.df.shape[0])\n","\n","    def __getitem__(self, idx):\n","        raise NotImplementedError(\"WRONG CLASS INSTANT.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"isYCKf5nWhvQ"},"source":["class UrbanSoundData(FewShotDataset):\n","    ''' The Dataset class. The __getitem__ function returns an\n","        STFT-label pair when we pass an index of the DataFrame. '''\n","\n","    def __init__(self, *args, **kwargs):\n","        super(UrbanSoundData, self).__init__(*args, **kwargs)\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, idx):\n","        index = int(idx)\n","        fname, data_dir = self.df[[\"slice_file_name\", \"fold\"]].iloc[index]\n","        fpath = \"fold\" + str(data_dir) + \"/\" + fname\n","        STFT = wav2feat(fpath)\n","        STFT = np.expand_dims(STFT, axis = -1)\n","        \n","        return torch.transpose(torch.from_numpy(STFT), 0, 2), self.labels[index]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufIRmx6jlUuZ"},"source":["class ClassBalancedSampler(Sampler):\n","    ''' A custom pytorch sampler. It samples \"num_inst\" examples for each of\n","        \"num_cl\" classes. \"num_per_class\" is the number of examples present in\n","        the current DataFrame. It reults a list of indexes. '''\n","\n","    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n","        self.num_per_class = num_per_class\n","        self.num_cl = num_cl\n","        self.num_inst = num_inst\n","        self.shuffle = shuffle\n","\n","    def __iter__(self):\n","        if self.shuffle:\n","            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n","        else:\n","            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n","        batch = [item for sublist in batch for item in sublist]\n","\n","        if self.shuffle:\n","            random.shuffle(batch)\n","        return iter(batch)\n","\n","    def __len__(self):\n","        return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bHFYkqZlUrf"},"source":["def get_data_loader(task, num_per_class = 1, split = 'train', shuffle = True):\n","    ''' The Dataloader function. \"num_per_class\" is the number\n","        of STFT-label pairs per class for train/test. '''\n","\n","    dataset = UrbanSoundData(task, split = split)\n","\n","    if split == 'train':\n","        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.train_num, shuffle = shuffle)\n","    else:\n","        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.test_num, shuffle = shuffle)\n","    loader = DataLoader(dataset, batch_size = num_per_class*task.num_classes, sampler = sampler)\n","\n","    return loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QxgsNTi1QRK"},"source":["Now, we will test if our functions work properly:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzHurMI-oqoE","outputId":"9c49f508-732c-4a20-c35d-6ba05336415a"},"source":["task = UrbanSoundTask(num_classes = 3, train_num = 5, test_num = 15, dfs = dfs_train)\n","print(task.train.shape, task.test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(15, 9) (45, 9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1dXiOfPSorxE"},"source":["dataset = UrbanSoundData(task)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qR6erkewukTR","outputId":"d81040ea-a278-4f2a-9034-14a1f53cac09"},"source":["print(\"Length of Dataset:\", len(dataset))\n","for i in range(len(dataset)):\n","    sample = dataset[i]\n","    print(\"Input shape =\", sample[0].shape, \"| Output class =\", sample[1])\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Length of Dataset: 15\n","Input shape = torch.Size([1, 401, 513]) | Output class = 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5yzfjLaMXA3","outputId":"ef62c050-7861-4fea-bc6a-de569e14d164"},"source":["import time\n","\n","dataloader = DataLoader(dataset, batch_size = 15, shuffle = True)\n","s_time = time.time()\n","for i_batch, sample_batched in enumerate(dataloader):\n","    print(\"index =\", i_batch, \":\\tBatch input =\", sample_batched[0].shape, \", Batch output =\", sample_batched[1].shape)\n","    if (i_batch == 2):\n","        break\n","print(\"Average time to load a batch =\", (time.time() - s_time)/2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["index = 0 :\tBatch input = torch.Size([15, 1, 401, 513]) , Batch output = torch.Size([15])\n","Average time to load a batch = 10.324092388153076\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qkjDkwfF7C4T"},"source":["# **Training**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lH2iug_UTRv-","outputId":"7bba856b-3500-47d4-aacc-1014e7d24924"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Running on\", device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SdQ5Bxj11fV","outputId":"76d108f4-7251-48fc-ded0-6c2b30aa3c86"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tue May 11 10:55:20 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8    26W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pj8Xwk0V_QFt"},"source":["''' 3 way 5 shot'''\n","CLASS_NUM = 3\n","SAMPLE_NUM_PER_CLASS = 5\n","BATCH_NUM_PER_CLASS = 15 # equivalent to number of test samples\n","\n","FEATURE_DIM = 64 # the depth of CNN encoder\n","INPUT_SIZE = 1536\n","RELATION_DIM = 8\n","\n","EPISODE = 5000\n","TEST_EPISODE = 100\n","\n","LEARNING_RATE = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzmAke2Z-BE7"},"source":["class CNNEncoder(nn.Module):\n","## the encoder module as explained in the paper, consists of 4 \"convolution-batchnorm-relu-maxpool\" blocks\n","    def __init__(self):\n","        super(CNNEncoder, self).__init__()\n","        self.layer1 = nn.Sequential(\n","                        nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(4))\n","        self.layer2 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 5, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.layer3 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU())\n","\n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        return out\n","\n","class RelationNetwork(nn.Module):\n","## the relation network module as explained in the paper\n","    def __init__(self, input_size, hidden_size):\n","        super(RelationNetwork, self).__init__()\n","        self.layer1 = nn.Sequential(\n","                        nn.Conv2d(128, 64, kernel_size = 3, padding = 1),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.layer2 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, 1)\n","\n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)\n","        out = F.relu(self.fc1(out))\n","        out = torch.sigmoid(self.fc2(out))\n","        return out\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","        m.weight.data.normal_(0, math.sqrt(2. / n))\n","        if m.bias is not None:\n","            m.bias.data.zero_()\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.fill_(1)\n","        m.bias.data.zero_()\n","    elif classname.find('Linear') != -1:\n","        n = m.weight.size(1)\n","        m.weight.data.normal_(0, 0.01)\n","        m.bias.data = torch.ones(m.bias.data.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hp1-QaiG_fL6"},"source":["train_losses = []\n","def train():\n","    ##function to initialise and train an entire pipeline end to end. \n","    ## arguments: None\n","    ## returns the trained encoder and relation networks\n","    ## initialise the embedding and relation network modules\n","    feature_encoder = CNNEncoder()\n","    relation_network = RelationNetwork(INPUT_SIZE, RELATION_DIM)\n","\n","    feature_encoder.apply(weights_init)\n","    relation_network.apply(weights_init)\n","\n","    feature_encoder.cuda(device)\n","    relation_network.cuda(device)\n","\n","    feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(), lr = LEARNING_RATE)\n","    feature_encoder_scheduler = StepLR(feature_encoder_optim, step_size = 10, gamma = 0.9)\n","\n","    relation_network_optim = torch.optim.Adam(relation_network.parameters(), lr = LEARNING_RATE)\n","    relation_network_scheduler = StepLR(relation_network_optim, step_size = 10, gamma = 0.9)\n","\n","    last_loss = 100.0\n","\n","    feature_encoder.zero_grad()\n","    relation_network.zero_grad()\n","\n","    for episode in range(EPISODE):\n","\n","        task = UrbanSoundTask(num_classes = CLASS_NUM, train_num = SAMPLE_NUM_PER_CLASS, test_num = BATCH_NUM_PER_CLASS, dfs = dfs_train)\n","\n","        sample_dataloader = get_data_loader(task, num_per_class = SAMPLE_NUM_PER_CLASS, split = 'train', shuffle = False)\n","        batch_dataloader = get_data_loader(task, num_per_class = BATCH_NUM_PER_CLASS, split = 'test', shuffle = True)\n","\n","        samples, sample_labels = sample_dataloader.__iter__().next()\n","        batches, batch_labels = batch_dataloader.__iter__().next()\n","\n","        sample_features = feature_encoder(Variable(samples).cuda(device))\n","        sample_features = sample_features.view(CLASS_NUM, SAMPLE_NUM_PER_CLASS, FEATURE_DIM, sample_features.shape[-2], sample_features.shape[-1])\n","\n","        sample_features = torch.sum(sample_features, 1).squeeze(1)\n","        batch_features = feature_encoder(Variable(batches).cuda(device))\n","\n","        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = torch.transpose(batch_features_ext, 0, 1)\n","\n","        relation_pairs = torch.cat((sample_features_ext, batch_features_ext), 2).view(-1, FEATURE_DIM*2, sample_features.shape[-2], sample_features.shape[-1])\n","        relations = relation_network(relation_pairs).view(-1, CLASS_NUM)\n","\n","        mse = nn.MSELoss().cuda(device)\n","        one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1, 1), 1)).cuda(device)\n","        loss = mse(relations, one_hot_labels)\n","\n","        if ((episode + 1)%10 == 0):\n","            print(\"Episode\", episode + 1 , \"=  loss\", loss.item())\n","        train_losses.append(loss.item())\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(), 0.5)\n","        torch.nn.utils.clip_grad_norm_(relation_network.parameters(), 0.5)\n","\n","        feature_encoder_optim.step()\n","        relation_network_optim.step()\n","\n","        feature_encoder_scheduler.step(episode)\n","        relation_network_scheduler.step(episode)\n","\n","        feature_encoder_optim.zero_grad()\n","        relation_network_optim.zero_grad()\n","\n","        if last_loss > loss.item():\n","            torch.save(feature_encoder.state_dict(),str(\"feature_encoder_\" + str(CLASS_NUM) + \"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n","            torch.save(relation_network.state_dict(),str(\"relation_network_\" + str(CLASS_NUM) + \"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n","\n","            last_loss = loss.item()\n","            print(\"\\tSave Networks for episode =\", episode + 1, \"| Loss =\", last_loss)\n","\n","    return feature_encoder, relation_network"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4bwj9ko_hWM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b82843f3-7865-44c0-81e3-9dec2649aec4"},"source":["feature_encoder, relation_network = train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\tSave Networks for episode = 1 | Loss = 0.38172605633735657\n","\tSave Networks for episode = 2 | Loss = 0.3104505240917206\n","\tSave Networks for episode = 3 | Loss = 0.24318157136440277\n","\tSave Networks for episode = 6 | Loss = 0.23615671694278717\n","\tSave Networks for episode = 9 | Loss = 0.23402686417102814\n","Episode 10 =  loss 0.22216422855854034\n","\tSave Networks for episode = 10 | Loss = 0.22216422855854034\n","Episode 20 =  loss 0.22822898626327515\n","Episode 30 =  loss 0.246372252702713\n","Episode 40 =  loss 0.227707639336586\n","\tSave Networks for episode = 42 | Loss = 0.2171739637851715\n","Episode 50 =  loss 0.2234395295381546\n","Episode 60 =  loss 0.21835489571094513\n","Episode 70 =  loss 0.21618591248989105\n","\tSave Networks for episode = 70 | Loss = 0.21618591248989105\n","\tSave Networks for episode = 71 | Loss = 0.21510711312294006\n","\tSave Networks for episode = 72 | Loss = 0.2134912759065628\n","\tSave Networks for episode = 77 | Loss = 0.21105758845806122\n","Episode 80 =  loss 0.21473067998886108\n","\tSave Networks for episode = 85 | Loss = 0.19736534357070923\n","Episode 90 =  loss 0.23232506215572357\n","Episode 100 =  loss 0.20859484374523163\n","Episode 110 =  loss 0.21270036697387695\n","Episode 120 =  loss 0.20796288549900055\n","Episode 130 =  loss 0.22192642092704773\n","Episode 140 =  loss 0.2164333462715149\n","Episode 150 =  loss 0.21060751378536224\n","\tSave Networks for episode = 152 | Loss = 0.1963663399219513\n","Episode 160 =  loss 0.20693376660346985\n","\tSave Networks for episode = 162 | Loss = 0.18965348601341248\n","Episode 170 =  loss 0.22480551898479462\n","Episode 180 =  loss 0.21803289651870728\n","Episode 190 =  loss 0.2111099511384964\n","Episode 200 =  loss 0.20498690009117126\n","\tSave Networks for episode = 201 | Loss = 0.1857749968767166\n","\tSave Networks for episode = 203 | Loss = 0.18392805755138397\n","Episode 210 =  loss 0.22611065208911896\n","\tSave Networks for episode = 212 | Loss = 0.1792251616716385\n","Episode 220 =  loss 0.18862389028072357\n","Episode 230 =  loss 0.18567347526550293\n","Episode 240 =  loss 0.1927689015865326\n","Episode 250 =  loss 0.21337135136127472\n","\tSave Networks for episode = 253 | Loss = 0.17688262462615967\n","Episode 260 =  loss 0.17870278656482697\n","Episode 270 =  loss 0.19003798067569733\n","Episode 280 =  loss 0.21879634261131287\n","\tSave Networks for episode = 288 | Loss = 0.17657402157783508\n","Episode 290 =  loss 0.21300844848155975\n","Episode 300 =  loss 0.1749681681394577\n","\tSave Networks for episode = 300 | Loss = 0.1749681681394577\n","Episode 310 =  loss 0.2126419097185135\n","Episode 320 =  loss 0.20980560779571533\n","\tSave Networks for episode = 326 | Loss = 0.16003906726837158\n","Episode 330 =  loss 0.1852528601884842\n","Episode 340 =  loss 0.2221112847328186\n","Episode 350 =  loss 0.19977274537086487\n","Episode 360 =  loss 0.24354632198810577\n","Episode 370 =  loss 0.20745447278022766\n","Episode 380 =  loss 0.17699052393436432\n","Episode 390 =  loss 0.18818384408950806\n","Episode 400 =  loss 0.1930326670408249\n","Episode 410 =  loss 0.24313247203826904\n","Episode 420 =  loss 0.24653875827789307\n","Episode 430 =  loss 0.19039061665534973\n","Episode 440 =  loss 0.18008309602737427\n","Episode 450 =  loss 0.22488148510456085\n","Episode 460 =  loss 0.19306035339832306\n","Episode 470 =  loss 0.22932828962802887\n","Episode 480 =  loss 0.17651398479938507\n","Episode 490 =  loss 0.1799795776605606\n","Episode 500 =  loss 0.18896551430225372\n","Episode 510 =  loss 0.21564695239067078\n","Episode 520 =  loss 0.18713468313217163\n","Episode 530 =  loss 0.21594303846359253\n","Episode 540 =  loss 0.22858691215515137\n","Episode 550 =  loss 0.22960001230239868\n","Episode 560 =  loss 0.21007192134857178\n","Episode 570 =  loss 0.17913198471069336\n","Episode 580 =  loss 0.19810567796230316\n","\tSave Networks for episode = 582 | Loss = 0.15567883849143982\n","Episode 590 =  loss 0.19214127957820892\n","Episode 600 =  loss 0.19192814826965332\n","Episode 610 =  loss 0.20755229890346527\n","Episode 620 =  loss 0.19903741776943207\n","Episode 630 =  loss 0.1776450276374817\n","Episode 640 =  loss 0.17217493057250977\n","Episode 650 =  loss 0.2011936604976654\n","Episode 660 =  loss 0.20964555442333221\n","Episode 670 =  loss 0.18842589855194092\n","Episode 680 =  loss 0.2024659365415573\n","Episode 690 =  loss 0.18526990711688995\n","Episode 700 =  loss 0.181457057595253\n","Episode 710 =  loss 0.17624050378799438\n","Episode 720 =  loss 0.22317631542682648\n","Episode 730 =  loss 0.18605785071849823\n","Episode 740 =  loss 0.1983364224433899\n","Episode 750 =  loss 0.16428567469120026\n","Episode 760 =  loss 0.16808442771434784\n","Episode 770 =  loss 0.22497600317001343\n","Episode 780 =  loss 0.18343967199325562\n","Episode 790 =  loss 0.22260932624340057\n","Episode 800 =  loss 0.19226369261741638\n","Episode 810 =  loss 0.21956822276115417\n","Episode 820 =  loss 0.18944407999515533\n","Episode 830 =  loss 0.1865929365158081\n","Episode 840 =  loss 0.1801164150238037\n","Episode 850 =  loss 0.17622517049312592\n","Episode 860 =  loss 0.24989846348762512\n","Episode 870 =  loss 0.24088019132614136\n","Episode 880 =  loss 0.19993361830711365\n","Episode 890 =  loss 0.21515804529190063\n","Episode 900 =  loss 0.18710634112358093\n","Episode 910 =  loss 0.16957253217697144\n","Episode 920 =  loss 0.1968550682067871\n","Episode 930 =  loss 0.24329650402069092\n","Episode 940 =  loss 0.18615393340587616\n","Episode 950 =  loss 0.23082247376441956\n","Episode 960 =  loss 0.21150653064250946\n","Episode 970 =  loss 0.18139950931072235\n","Episode 980 =  loss 0.20671263337135315\n","Episode 990 =  loss 0.1807558387517929\n","Episode 1000 =  loss 0.2145751416683197\n","Episode 1010 =  loss 0.21659624576568604\n","Episode 1020 =  loss 0.22560057044029236\n","Episode 1030 =  loss 0.20216119289398193\n","Episode 1040 =  loss 0.21354801952838898\n","Episode 1050 =  loss 0.23035885393619537\n","Episode 1060 =  loss 0.1920906901359558\n","Episode 1070 =  loss 0.18157939612865448\n","Episode 1080 =  loss 0.24109451472759247\n","Episode 1090 =  loss 0.20056486129760742\n","Episode 1100 =  loss 0.1888635903596878\n","Episode 1110 =  loss 0.1881544589996338\n","Episode 1120 =  loss 0.19959679245948792\n","Episode 1130 =  loss 0.19373081624507904\n","Episode 1140 =  loss 0.2153506726026535\n","Episode 1150 =  loss 0.19572891294956207\n","Episode 1160 =  loss 0.1830596774816513\n","Episode 1170 =  loss 0.20431433618068695\n","Episode 1180 =  loss 0.19231702387332916\n","Episode 1190 =  loss 0.23758338391780853\n","Episode 1200 =  loss 0.19943177700042725\n","Episode 1210 =  loss 0.18268828094005585\n","Episode 1220 =  loss 0.2203073799610138\n","Episode 1230 =  loss 0.21157802641391754\n","Episode 1240 =  loss 0.18922339379787445\n","Episode 1250 =  loss 0.22598624229431152\n","Episode 1260 =  loss 0.17779092490673065\n","Episode 1270 =  loss 0.19593748450279236\n","Episode 1280 =  loss 0.18739433586597443\n","Episode 1290 =  loss 0.19511398673057556\n","Episode 1300 =  loss 0.1986590474843979\n","Episode 1310 =  loss 0.18315672874450684\n","\tSave Networks for episode = 1314 | Loss = 0.15217915177345276\n","Episode 1320 =  loss 0.21823447942733765\n","Episode 1330 =  loss 0.2190546989440918\n","Episode 1340 =  loss 0.2177245318889618\n","Episode 1350 =  loss 0.21394789218902588\n","Episode 1360 =  loss 0.21275854110717773\n","Episode 1370 =  loss 0.17480143904685974\n","\tSave Networks for episode = 1375 | Loss = 0.14982938766479492\n","Episode 1380 =  loss 0.18897810578346252\n","Episode 1390 =  loss 0.1996602565050125\n","Episode 1400 =  loss 0.1869623064994812\n","Episode 1410 =  loss 0.1901940256357193\n","Episode 1420 =  loss 0.19032180309295654\n","Episode 1430 =  loss 0.21631935238838196\n","Episode 1440 =  loss 0.23592950403690338\n","Episode 1450 =  loss 0.18209600448608398\n","Episode 1460 =  loss 0.1988586038351059\n","Episode 1470 =  loss 0.23873403668403625\n","Episode 1480 =  loss 0.19718757271766663\n","Episode 1490 =  loss 0.22210751473903656\n","Episode 1500 =  loss 0.1875624656677246\n","Episode 1510 =  loss 0.1939927190542221\n","Episode 1520 =  loss 0.19170543551445007\n","Episode 1530 =  loss 0.20568881928920746\n","Episode 1540 =  loss 0.19027511775493622\n","Episode 1550 =  loss 0.18440474569797516\n","Episode 1560 =  loss 0.18150225281715393\n","Episode 1570 =  loss 0.19307973980903625\n","Episode 1580 =  loss 0.18349117040634155\n","Episode 1590 =  loss 0.1908383071422577\n","Episode 1600 =  loss 0.2134392261505127\n","Episode 1610 =  loss 0.22512254118919373\n","Episode 1620 =  loss 0.21437574923038483\n","Episode 1630 =  loss 0.24420680105686188\n","Episode 1640 =  loss 0.21126115322113037\n","Episode 1650 =  loss 0.17569604516029358\n","Episode 1660 =  loss 0.20141281187534332\n","Episode 1670 =  loss 0.21468262374401093\n","Episode 1680 =  loss 0.2046431452035904\n","Episode 1690 =  loss 0.1834949254989624\n","Episode 1700 =  loss 0.19049982726573944\n","Episode 1710 =  loss 0.23397819697856903\n","Episode 1720 =  loss 0.1873036026954651\n","Episode 1730 =  loss 0.19257234036922455\n","Episode 1740 =  loss 0.20901019871234894\n","Episode 1750 =  loss 0.1842532902956009\n","Episode 1760 =  loss 0.23787572979927063\n","Episode 1770 =  loss 0.19532835483551025\n","Episode 1780 =  loss 0.21937093138694763\n","Episode 1790 =  loss 0.17544490098953247\n","Episode 1800 =  loss 0.19314023852348328\n","Episode 1810 =  loss 0.16700029373168945\n","Episode 1820 =  loss 0.20654703676700592\n","Episode 1830 =  loss 0.18987901508808136\n","Episode 1840 =  loss 0.2006654590368271\n","Episode 1850 =  loss 0.2052246332168579\n","Episode 1860 =  loss 0.18748465180397034\n","Episode 1870 =  loss 0.20067381858825684\n","Episode 1880 =  loss 0.18977385759353638\n","Episode 1890 =  loss 0.20124836266040802\n","Episode 1900 =  loss 0.1943391114473343\n","Episode 1910 =  loss 0.19868114590644836\n","Episode 1920 =  loss 0.20742608606815338\n","Episode 1930 =  loss 0.2191230207681656\n","Episode 1940 =  loss 0.21825021505355835\n","Episode 1950 =  loss 0.18264180421829224\n","Episode 1960 =  loss 0.19227910041809082\n","Episode 1970 =  loss 0.19167567789554596\n","Episode 1980 =  loss 0.2213832587003708\n","Episode 1990 =  loss 0.23117436468601227\n","Episode 2000 =  loss 0.20993942022323608\n","Episode 2010 =  loss 0.19096624851226807\n","Episode 2020 =  loss 0.19625110924243927\n","Episode 2030 =  loss 0.16818350553512573\n","Episode 2040 =  loss 0.22795113921165466\n","Episode 2050 =  loss 0.2264830470085144\n","Episode 2060 =  loss 0.1915341168642044\n","Episode 2070 =  loss 0.18048149347305298\n","Episode 2080 =  loss 0.23939460515975952\n","Episode 2090 =  loss 0.19823986291885376\n","Episode 2100 =  loss 0.19188885390758514\n","Episode 2110 =  loss 0.16262014210224152\n","Episode 2120 =  loss 0.1919235736131668\n","Episode 2130 =  loss 0.17747750878334045\n","Episode 2140 =  loss 0.1732621043920517\n","Episode 2150 =  loss 0.17671680450439453\n","Episode 2160 =  loss 0.177298441529274\n","Episode 2170 =  loss 0.21733932197093964\n","Episode 2180 =  loss 0.20951057970523834\n","Episode 2190 =  loss 0.20107848942279816\n","Episode 2200 =  loss 0.22553801536560059\n","Episode 2210 =  loss 0.20858259499073029\n","Episode 2220 =  loss 0.2010602205991745\n","Episode 2230 =  loss 0.19989483058452606\n","Episode 2240 =  loss 0.18638907372951508\n","Episode 2250 =  loss 0.23877501487731934\n","Episode 2260 =  loss 0.17722809314727783\n","Episode 2270 =  loss 0.20056691765785217\n","Episode 2280 =  loss 0.19388781487941742\n","Episode 2290 =  loss 0.23791339993476868\n","Episode 2300 =  loss 0.17060309648513794\n","Episode 2310 =  loss 0.15884003043174744\n","Episode 2320 =  loss 0.22307388484477997\n","\tSave Networks for episode = 2328 | Loss = 0.1493254452943802\n","Episode 2330 =  loss 0.22563844919204712\n","Episode 2340 =  loss 0.24523866176605225\n","Episode 2350 =  loss 0.18043261766433716\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8FntJSWAIZ8"},"source":["import matplotlib.pyplot as plt\n","plt.plot(train_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yKv5OHu0nkr"},"source":["# **Test**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"7AYzKIXNzXyN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1626d4ab-ec37-43a7-b688-b116f711148a"},"source":["feature_encoder = CNNEncoder()\n","relation_network = RelationNetwork(INPUT_SIZE, RELATION_DIM)\n","\n","feature_encoder.apply(weights_init)\n","relation_network.apply(weights_init)\n","\n","feature_encoder.cuda(device)\n","relation_network.cuda(device)\n","\n","feature_encoder.load_state_dict(torch.load(str(\"feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n","relation_network.load_state_dict(torch.load(str(\"relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"XPpO1ip6zMFS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5b8036a-5d56-49ae-f21c-2b49c2111a6a"},"source":["total_rewards = 0.0\n","with torch.no_grad():\n","    for i in range(TEST_EPISODE):\n","        task = UrbanSoundTask(num_classes = CLASS_NUM, train_num = SAMPLE_NUM_PER_CLASS, test_num = BATCH_NUM_PER_CLASS, dfs = dfs_test, split = 'test')\n","        sample_dataloader = get_data_loader(task, num_per_class = SAMPLE_NUM_PER_CLASS, split = 'train', shuffle = False)\n","        batch_dataloader = get_data_loader(task, num_per_class = BATCH_NUM_PER_CLASS, split = 'test', shuffle = True)\n","\n","        samples, sample_labels = sample_dataloader.__iter__().next()\n","        batches, batch_labels = batch_dataloader.__iter__().next()\n","\n","        sample_features = feature_encoder(Variable(samples).cuda(device))\n","        sample_features = sample_features.view(CLASS_NUM, SAMPLE_NUM_PER_CLASS, FEATURE_DIM, sample_features.shape[-2], sample_features.shape[-1])\n","        sample_features = torch.sum(sample_features, 1).squeeze(1)\n","        batch_features = feature_encoder(Variable(batches).cuda(device))\n","\n","        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = torch.transpose(batch_features_ext, 0, 1)\n","\n","        relation_pairs = torch.cat((sample_features_ext, batch_features_ext), 2).view(-1, FEATURE_DIM*2, sample_features.shape[-2], sample_features.shape[-1])\n","        relations = relation_network(relation_pairs).view(-1, CLASS_NUM)\n","\n","        _, predict_labels = torch.max(relations.data, 1)\n","\n","        rewards = [1 if predict_labels[j] == batch_labels[j] else 0 for j in range(CLASS_NUM*BATCH_NUM_PER_CLASS)]\n","        total_rewards += np.sum(rewards)\n","\n","    test_accuracy = total_rewards/1.0/CLASS_NUM/BATCH_NUM_PER_CLASS/TEST_EPISODE\n","\n","    print(\"test accuracy:\", test_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test accuracy: 0.5082222222222222\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Dmw5UByEa-Z"},"source":[""],"execution_count":null,"outputs":[]}]}