{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCASE1-FewShot.ipynb","provenance":[{"file_id":"1gc5WM0DfKkPxNs0a9HV7JO37w8Zsp24F","timestamp":1620732371936}],"collapsed_sections":["MXkAa6tfDtWf","U57R-okWpZN2","qkjDkwfF7C4T"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X87PzfZtDJn4","executionInfo":{"status":"ok","timestamp":1620738405850,"user_tz":-330,"elapsed":24308,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"b4fefff4-4a7a-4bdf-d778-e0767e4dc764"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MXkAa6tfDtWf"},"source":["# **Data Loader**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"oGRNm2BxI75l"},"source":["''' Split for number of classes in training and test '''\n","num_sampleclasses = 7\n","num_fewshotclasses = 3 #atleast two\n","\n","''' Number of audio-label pairs in Training (sample) and Test (fewshot) '''\n","sample_train = 600\n","sample_val = 0\n","sample_test = 0\n","\n","fewshot_train = 0\n","fewshot_val = 60\n","fewshot_test = 200\n","\n","''' Audio to STFT hyperparameters '''\n","sampling_rate = 44100\n","row_len = 513 # Number of columns: 1 + n_fft/2\n","col_len = 401 # Number of rows: 1 + (sampling_rate*audio_duration)/(0.01*sampling_rate); 0.01*sampling_rate = hop \n","# audio_length = sampling_rate*audio_duration\n","# audio_duration = 4 seconds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0CjBC8fkwU3","executionInfo":{"status":"ok","timestamp":1620738405852,"user_tz":-330,"elapsed":4535,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"d2ca3bed-5548-4060-cfed-3818babe0722"},"source":["%cd \"/content/drive/MyDrive/DCASE-task1\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/DCASE-task1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DTrJvygok3nq"},"source":["import numpy as np\n","import pandas as pd\n","\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","\n","import librosa\n","\n","from sklearn.utils import shuffle\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import Sampler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWzu7OMpmlxV"},"source":["Number of audio-label pairs for each class. Clearly, *car horn* and *gun shot* are *rare classes*. We will always include them in test dataset. \n","\n","\n","The third class for the test set in selected randomly. *FEWSHOT_CLASSES* are test set classes and *SAMPLE_CLASSES* are training set classes."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGV73tXalaKp","executionInfo":{"status":"ok","timestamp":1620738412989,"user_tz":-330,"elapsed":11660,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"cf34b210-5613-41b5-e969-474c52420c52"},"source":["df = pd.read_csv(\"dcase1.csv\")\n","df[\"class\"].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["metro_station        2304\n","street_pedestrian    2304\n","park                 2304\n","street_traffic       2304\n","bus                  2304\n","metro                2304\n","public_square        2303\n","shopping_mall        2303\n","tram                 2303\n","airport              2302\n","Name: class, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2b0mL09Ja8o","executionInfo":{"status":"ok","timestamp":1620738412989,"user_tz":-330,"elapsed":11653,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"fd9b42a2-01fa-43e8-eb8d-b6fc2f81cb15"},"source":["CLASSES = list(df[\"class\"].unique())\n","\n","random.shuffle(CLASSES)\n","SAMPLE_CLASSES = CLASSES[:num_sampleclasses]\n","FEWSHOT_CLASSES = CLASSES[num_sampleclasses:]\n","\n","print(SAMPLE_CLASSES, FEWSHOT_CLASSES)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['street_pedestrian', 'bus', 'park', 'tram', 'shopping_mall', 'metro_station', 'metro'] ['street_traffic', 'airport', 'public_square']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXWgBTcEl1Cs"},"source":["def get_data(class_name, n_train, n_val, n_test):\n","    df_class = df.loc[df[\"class\"] == class_name]\n","    indexes = [i for i in range(df_class.shape[0])]\n","    random.shuffle(indexes)\n","\n","    df_class_train = df_class.iloc[indexes[:n_train]]\n","    df_class_val = df_class.iloc[indexes[n_train:(n_train + n_val)]]\n","    df_class_test = df_class.iloc[indexes[(n_train + n_val):(n_train + n_val + n_test)]]\n","\n","    return df_class_train, df_class_val, df_class_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4zJJ56eywxe"},"source":["SAMPLE_data_train = [None]*num_sampleclasses\n","SAMPLE_data_val = [None]*num_sampleclasses\n","SAMPLE_data_test = [None]*num_sampleclasses\n","\n","for i in range(num_sampleclasses):\n","    SAMPLE_data_train[i], SAMPLE_data_val[i], SAMPLE_data_test[i] = get_data(SAMPLE_CLASSES[i], sample_train, sample_val, sample_test)\n","\n","FS_data_train = [None]*num_fewshotclasses\n","FS_data_val = [None]*num_fewshotclasses\n","FS_data_test = [None]*num_fewshotclasses\n","\n","for i in range(num_fewshotclasses):\n","    FS_data_train[i], FS_data_val[i], FS_data_test[i] = get_data(FEWSHOT_CLASSES[i], fewshot_train, fewshot_val, fewshot_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vlJ8xZMgOlgy"},"source":["df_train = pd.concat((SAMPLE_data_train + FS_data_train), ignore_index = True)\n","df_val = pd.concat((SAMPLE_data_val + FS_data_val), ignore_index = True)\n","df_test = pd.concat((SAMPLE_data_test + FS_data_test), ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Fnhpv2unwgi"},"source":["So far, we have randomly selected\n"," \n","\n","*   600 (*sample_train*) audio-label pairs per class for training dataset.\n","*   20 (*fewshot_val*) audio-label pairs per class for validation dataset.\n","*   200 (*fewshot_test*) audio-label pairs per class for test dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWC-OiiUO8R9","executionInfo":{"status":"ok","timestamp":1620738412991,"user_tz":-330,"elapsed":11640,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"72cfc7d1-68f2-4507-a1c6-620da8e0d60e"},"source":["print(list(df_train[\"class\"].value_counts()))\n","print(list(df_val[\"class\"].value_counts()))\n","print(list(df_test[\"class\"].value_counts()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[600, 600, 600, 600, 600, 600, 600]\n","[60, 60, 60]\n","[200, 200, 200]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w6P5IkyhxVVj"},"source":["# df_train.to_csv(\"\", index = False)\n","# df_val.to_csv(\"\", index = False)\n","# df_test.to_csv(\"\", index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_8wQA4hydIf"},"source":["df_tmp = pd.read_csv(\"dcase1.csv\")\n","_labels = list(df_tmp[\"class\"].unique())\n","label_idx = {label: i for i, label in enumerate(_labels)}\n","n_classes = len(df_tmp[\"class\"].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGK4u5qWodDP"},"source":["**Divide each of train, validation and test into smaller DataFrames for Few-Shot learning**"]},{"cell_type":"code","metadata":{"id":"8KY2Quu8OCYW"},"source":["def CreatDataFolders(df, n, samples, per_df):\n","    df[\"label_idx\"] = df[\"class\"].apply(lambda x : label_idx[x])\n","    df.sort_values(by = \"label_idx\", inplace = True)\n","\n","    a = 0\n","    b = per_df\n","    dfs = []\n","    for _ in range(n):\n","        tmp = []\n","        for i in range(int(samples/per_df)):\n","            tmp.append(df.iloc[a:b])\n","            a += per_df\n","            b += per_df\n","        dfs.append(tmp)\n","    \n","    return dfs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIkrFfQHK0fM"},"source":["dfs_train = CreatDataFolders(df_train, num_sampleclasses, sample_train, 30)\n","dfs_val = CreatDataFolders(df_val, num_fewshotclasses, fewshot_val, 20)\n","dfs_test = CreatDataFolders(df_test, num_fewshotclasses, fewshot_test, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U57R-okWpZN2"},"source":["# **Utility Functions**\n","\n","---"]},{"cell_type":"code","metadata":{"id":"ntkjDQrsSE3D"},"source":["def wav2feat(wavfile, Fs = sampling_rate):\n","    ''' input: file path to an audio file (.wav file)\n","        output: padded STFT '''\n","        \n","    x, _ = librosa.core.load(wavfile, sr = Fs, mono = True)\n","    hop = int(0.01*Fs) # 10ms\n","    win = int(0.02*Fs) # 20ms\n","    X = librosa.stft(x, n_fft = 1024, hop_length = hop, win_length = win, window = 'hann', center = True, pad_mode = \"reflect\")\n","    X = np.abs(X)\n","\n","    if X.shape[1] > col_len:\n","        max_offset = X.shape[1] - col_len\n","        offset = np.random.randint(max_offset)\n","        X = X[:, offset : (col_len + offset)]\n","    else:\n","        if X.shape[1] < col_len:\n","            max_offset = col_len - X.shape[1]\n","            offset = np.random.randint(max_offset)\n","        else:\n","            offset = 0\n","        X = np.pad(X, ((0, 0), (offset, col_len - X.shape[1] - offset)), \"constant\")\n","\n","    return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSP4FyxhuBor"},"source":["class DCASE1Task(object):\n","    ''' \"num_classes is no. of classes per episode randomly\n","        selected from the pool of train classes.\n","        \"train_num\"/\"test_num\" is number of samples per class. '''\n","\n","    def __init__(self, num_classes = 3, train_num = 5, test_num = 15, dfs = None, split ='train'):\n","        self.num_classes = num_classes\n","        self.train_num = train_num\n","        self.test_num = test_num\n","        self.dfs = dfs\n","        self.mode = split\n","\n","        self.train = pd.DataFrame()\n","        self.test = pd.DataFrame()\n","        self.train_labels = []\n","        self.test_labels = []\n","\n","        if (self.mode == 'train'):\n","            sample_idx = random.sample([i for i in range(num_sampleclasses)], self.num_classes)\n","        else:\n","            sample_idx = random.sample([i for i in range(num_fewshotclasses)], self.num_classes)\n","\n","        list_dfs = []\n","        for idx in sample_idx:\n","            list_dfs.append(random.sample(self.dfs[idx], 1))\n","        \n","        for i, df in enumerate(list_dfs):\n","            df = shuffle(df[0])\n","            self.train = self.train.append(df[:train_num])\n","            self.train_labels.extend([i for j in range(train_num)])\n","\n","            self.test = self.test.append(df[train_num:(train_num + test_num)])\n","            self.test_labels.extend([i for j in range(test_num)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DojWzImaQjhU"},"source":["class FewShotDataset(Dataset):\n","    ''' It is a custom pytorch Dataset.\n","        input: An object of \"DCASE1Task\" class. '''\n","\n","    def __init__(self, task, split = 'train'):\n","        self.task = task\n","        self.mode = split\n","        self.df = self.task.train if self.mode == 'train' else self.task.test\n","        self.labels = self.task.train_labels if self.mode == 'train' else self.task.test_labels\n","\n","    def __len__(self):\n","        return len(self.df.shape[0])\n","\n","    def __getitem__(self, idx):\n","        raise NotImplementedError(\"WRONG CLASS INSTANT.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"isYCKf5nWhvQ"},"source":["class DCASE1Data(FewShotDataset):\n","    ''' The Dataset class. The __getitem__ function returns an\n","        STFT-label pair when we pass an index of the DataFrame. '''\n","\n","    def __init__(self, *args, **kwargs):\n","        super(DCASE1Data, self).__init__(*args, **kwargs)\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, idx):\n","        index = int(idx)\n","        fname = self.df['file_name'].iloc[index]\n","        STFT = wav2feat(fname)\n","        STFT = np.expand_dims(STFT, axis = -1)\n","        \n","        return torch.transpose(torch.from_numpy(STFT), 0, 2), self.labels[index]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufIRmx6jlUuZ"},"source":["class ClassBalancedSampler(Sampler):\n","    ''' A custom pytorch sampler. It samples \"num_inst\" examples for each of\n","        \"num_cl\" classes. \"num_per_class\" is the number of examples present in\n","        the current DataFrame. It reults a list of indexes. '''\n","\n","    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n","        self.num_per_class = num_per_class\n","        self.num_cl = num_cl\n","        self.num_inst = num_inst\n","        self.shuffle = shuffle\n","\n","    def __iter__(self):\n","        if self.shuffle:\n","            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n","        else:\n","            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n","        batch = [item for sublist in batch for item in sublist]\n","\n","        if self.shuffle:\n","            random.shuffle(batch)\n","        return iter(batch)\n","\n","    def __len__(self):\n","        return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bHFYkqZlUrf"},"source":["def get_data_loader(task, num_per_class = 1, split = 'train', shuffle = True):\n","    ''' The Dataloader function. \"num_per_class\" is the number\n","        of STFT-label pairs per class for train/test. '''\n","\n","    dataset = DCASE1Data(task, split = split)\n","\n","    if split == 'train':\n","        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.train_num, shuffle = shuffle)\n","    else:\n","        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.test_num, shuffle = shuffle)\n","    loader = DataLoader(dataset, batch_size = num_per_class*task.num_classes, sampler = sampler)\n","\n","    return loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkjDkwfF7C4T"},"source":["# **Training**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lH2iug_UTRv-","executionInfo":{"status":"ok","timestamp":1620738414124,"user_tz":-330,"elapsed":1116,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"c1e61f1a-4777-4f28-912f-6895c0354d8c"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Running on\", device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SdQ5Bxj11fV","executionInfo":{"status":"ok","timestamp":1620738414124,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"3cd3f8b4-9d44-43ea-e8d7-5760791840f5"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tue May 11 13:06:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pj8Xwk0V_QFt"},"source":["''' 3 way 5 shot'''\n","CLASS_NUM = 3\n","SAMPLE_NUM_PER_CLASS = 5\n","BATCH_NUM_PER_CLASS = 15 # equivalent to number of test samples\n","\n","FEATURE_DIM = 64 # the depth of CNN encoder\n","INPUT_SIZE = 1536\n","RELATION_DIM = 8\n","\n","EPISODE = 5000\n","TEST_EPISODE = 100\n","\n","LEARNING_RATE = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzmAke2Z-BE7"},"source":["class CNNEncoder(nn.Module):\n","    ## the encoder module as explained in the paper, consists of 4 \"convolution-batchnorm-relu-maxpool\" blocks\n","    def __init__(self):\n","        super(CNNEncoder, self).__init__()\n","        self.layer1 = nn.Sequential(\n","                        nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(4))\n","        self.layer2 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 5, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.layer3 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 0),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU())\n","\n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        return out\n","\n","class RelationNetwork(nn.Module):\n","   ## the relation network module as explained in the paper\n","    def __init__(self, input_size, hidden_size):\n","        super(RelationNetwork, self).__init__()\n","        self.layer1 = nn.Sequential(\n","                        nn.Conv2d(128, 64, kernel_size = 3, padding = 1),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.layer2 = nn.Sequential(\n","                        nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n","                        nn.BatchNorm2d(64, momentum = 1, affine = True),\n","                        nn.ReLU(),\n","                        nn.MaxPool2d(2))\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, 1)\n","\n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)\n","        out = F.relu(self.fc1(out))\n","        out = torch.sigmoid(self.fc2(out))\n","        return out\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","        m.weight.data.normal_(0, math.sqrt(2. / n))\n","        if m.bias is not None:\n","            m.bias.data.zero_()\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.fill_(1)\n","        m.bias.data.zero_()\n","    elif classname.find('Linear') != -1:\n","        n = m.weight.size(1)\n","        m.weight.data.normal_(0, 0.01)\n","        m.bias.data = torch.ones(m.bias.data.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hp1-QaiG_fL6"},"source":["train_losses = [] ## list to keep check on losses\n","def train(): \n","    ##function to initialise and train an entire pipeline end to end. \n","    ## arguments: None\n","    ## returns the trained encoder and relation networks\n","    ## initialise the embedding and relation network modules\n","    feature_encoder = CNNEncoder()\n","    relation_network = RelationNetwork(INPUT_SIZE, RELATION_DIM)\n","\n","    feature_encoder.apply(weights_init)\n","    relation_network.apply(weights_init)\n","\n","    feature_encoder.cuda(device)\n","    relation_network.cuda(device)\n","\n","    ## initialising the optimizers for the modules\n","\n","    feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(), lr = LEARNING_RATE)\n","    feature_encoder_scheduler = StepLR(feature_encoder_optim, step_size = 10, gamma = 0.9)\n","\n","    relation_network_optim = torch.optim.Adam(relation_network.parameters(), lr = LEARNING_RATE)\n","    relation_network_scheduler = StepLR(relation_network_optim, step_size = 10, gamma = 0.9)\n","\n","    last_loss = 100.0\n","    counter = 0\n","    feature_encoder.zero_grad()\n","    relation_network.zero_grad()\n","\n","    for episode in range(EPISODE):\n","\n","        task = DCASE1Task(num_classes = CLASS_NUM, train_num = SAMPLE_NUM_PER_CLASS, test_num = BATCH_NUM_PER_CLASS, dfs = dfs_train)\n","\n","        sample_dataloader = get_data_loader(task, num_per_class = SAMPLE_NUM_PER_CLASS, split = 'train', shuffle = False)\n","        batch_dataloader = get_data_loader(task, num_per_class = BATCH_NUM_PER_CLASS, split = 'test', shuffle = True)\n","\n","        samples, sample_labels = sample_dataloader.__iter__().next()\n","        batches, batch_labels = batch_dataloader.__iter__().next()\n","\n","        sample_features = feature_encoder(Variable(samples).cuda(device))\n","        sample_features = sample_features.view(CLASS_NUM, SAMPLE_NUM_PER_CLASS, FEATURE_DIM, sample_features.shape[-2], sample_features.shape[-1])\n","\n","        sample_features = torch.sum(sample_features, 1).squeeze(1)\n","        batch_features = feature_encoder(Variable(batches).cuda(device))\n","\n","        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = torch.transpose(batch_features_ext, 0, 1)\n","\n","        relation_pairs = torch.cat((sample_features_ext, batch_features_ext), 2).view(-1, FEATURE_DIM*2, sample_features.shape[-2], sample_features.shape[-1])\n","        relations = relation_network(relation_pairs).view(-1, CLASS_NUM)\n","\n","        mse = nn.MSELoss().cuda(device)\n","        one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1, 1), 1)).cuda(device)\n","        loss = mse(relations, one_hot_labels)\n","\n","        if ((episode + 1)%10 == 0):\n","            print(\"Episode\", episode + 1 , \"=  loss\", loss.item())\n","        train_losses.append(loss.item())\n","\n","        loss.backward()\n","        ## clipping gradient to stabilise training\n","        torch.nn.utils.clip_grad_norm_(feature_encoder.parameters(), 0.5)\n","        torch.nn.utils.clip_grad_norm_(relation_network.parameters(), 0.5)\n","\n","        feature_encoder_optim.step()\n","        relation_network_optim.step()\n","\n","        feature_encoder_scheduler.step(episode)\n","        relation_network_scheduler.step(episode)\n","\n","        feature_encoder_optim.zero_grad()\n","        relation_network_optim.zero_grad()\n","\n","        if last_loss > loss.item():\n","            torch.save(feature_encoder.state_dict(),str(\"feature_encoder_\" + str(CLASS_NUM) + \"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n","            torch.save(relation_network.state_dict(),str(\"relation_network_\" + str(CLASS_NUM) + \"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n","\n","            last_loss = loss.item()\n","            print(\"\\tSave Networks for episode =\", episode + 1, \"| Loss =\", last_loss)\n","        else:\n","            counter += 1\n","            if (counter > 50):\n","                print(\"BREAKING\")\n","                break\n","\n","    return feature_encoder, relation_network"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4bwj9ko_hWM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620739947408,"user_tz":-330,"elapsed":1524107,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"932dc59d-15a1-4d34-8e42-3b5a194d9ba4"},"source":["feature_encoder, relation_network = train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\tSave Networks for episode = 1 | Loss = 0.3826756775379181\n","\tSave Networks for episode = 2 | Loss = 0.28079935908317566\n","\tSave Networks for episode = 3 | Loss = 0.23981617391109467\n","\tSave Networks for episode = 4 | Loss = 0.23790961503982544\n","\tSave Networks for episode = 6 | Loss = 0.2235773354768753\n","\tSave Networks for episode = 8 | Loss = 0.2212783694267273\n","Episode 10 =  loss 0.22811612486839294\n","\tSave Networks for episode = 11 | Loss = 0.2201368510723114\n","\tSave Networks for episode = 17 | Loss = 0.21396642923355103\n","Episode 20 =  loss 0.21504329144954681\n","\tSave Networks for episode = 21 | Loss = 0.20793649554252625\n","\tSave Networks for episode = 24 | Loss = 0.20714329183101654\n","\tSave Networks for episode = 26 | Loss = 0.20014405250549316\n","Episode 30 =  loss 0.21371960639953613\n","\tSave Networks for episode = 33 | Loss = 0.1889353096485138\n","\tSave Networks for episode = 36 | Loss = 0.18848371505737305\n","\tSave Networks for episode = 38 | Loss = 0.1790793538093567\n","\tSave Networks for episode = 39 | Loss = 0.17785373330116272\n","Episode 40 =  loss 0.19313901662826538\n","Episode 50 =  loss 0.21546238660812378\n","Episode 60 =  loss 0.19905129075050354\n","\tSave Networks for episode = 66 | Loss = 0.1555064171552658\n","BREAKING\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8FntJSWAIZ8","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1620739948320,"user_tz":-330,"elapsed":1524207,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"028e434f-eadd-41aa-afac-9362d1667982"},"source":["import matplotlib.pyplot as plt\n","plt.plot(train_losses)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f07781c6b90>]"]},"metadata":{"tags":[]},"execution_count":27},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"0yKv5OHu0nkr"},"source":["# **Test**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"7AYzKIXNzXyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620739948321,"user_tz":-330,"elapsed":1523388,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"7890fd51-3364-4227-f48b-02310081d403"},"source":["feature_encoder = CNNEncoder()\n","relation_network = RelationNetwork(INPUT_SIZE, RELATION_DIM)\n","\n","feature_encoder.apply(weights_init)\n","relation_network.apply(weights_init)\n","\n","feature_encoder.cuda(device)\n","relation_network.cuda(device)\n","\n","feature_encoder.load_state_dict(torch.load(str(\"feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n","relation_network.load_state_dict(torch.load(str(\"relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"XPpO1ip6zMFS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620740372217,"user_tz":-330,"elapsed":1946781,"user":{"displayName":"Machine Learning","photoUrl":"","userId":"02931914519755917022"}},"outputId":"3069075c-280a-496a-b524-95dbdb204e16"},"source":["total_rewards = 0.0\n","with torch.no_grad():\n","    for i in range(TEST_EPISODE):\n","        task = DCASE1Task(num_classes = CLASS_NUM, train_num = SAMPLE_NUM_PER_CLASS, test_num = BATCH_NUM_PER_CLASS, dfs = dfs_test, split = 'test')\n","        sample_dataloader = get_data_loader(task, num_per_class = SAMPLE_NUM_PER_CLASS, split = 'train', shuffle = False)\n","        batch_dataloader = get_data_loader(task, num_per_class = BATCH_NUM_PER_CLASS, split = 'test', shuffle = True)\n","\n","        samples, sample_labels = sample_dataloader.__iter__().next()\n","        batches, batch_labels = batch_dataloader.__iter__().next()\n","\n","        sample_features = feature_encoder(Variable(samples).cuda(device))\n","        sample_features = sample_features.view(CLASS_NUM, SAMPLE_NUM_PER_CLASS, FEATURE_DIM, sample_features.shape[-2], sample_features.shape[-1])\n","        sample_features = torch.sum(sample_features, 1).squeeze(1)\n","        batch_features = feature_encoder(Variable(batches).cuda(device))\n","\n","        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM, 1, 1, 1, 1)\n","        batch_features_ext = torch.transpose(batch_features_ext, 0, 1)\n","\n","        relation_pairs = torch.cat((sample_features_ext, batch_features_ext), 2).view(-1, FEATURE_DIM*2, sample_features.shape[-2], sample_features.shape[-1])\n","        relations = relation_network(relation_pairs).view(-1, CLASS_NUM)\n","\n","        _, predict_labels = torch.max(relations.data, 1)\n","\n","        rewards = [1 if predict_labels[j] == batch_labels[j] else 0 for j in range(CLASS_NUM*BATCH_NUM_PER_CLASS)]\n","        total_rewards += np.sum(rewards)\n","\n","    test_accuracy = total_rewards/1.0/CLASS_NUM/BATCH_NUM_PER_CLASS/TEST_EPISODE\n","\n","    print(\"test accuracy:\", test_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test accuracy: 0.46\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Dmw5UByEa-Z"},"source":[""],"execution_count":null,"outputs":[]}]}